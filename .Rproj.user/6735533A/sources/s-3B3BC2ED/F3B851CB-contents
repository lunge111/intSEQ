\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
\usepackage{breakurl}
\begin{document}
<<setup, include=FALSE, cache=FALSE, echo=FALSE>>=
library(knitr)
# set global chunk options
opts_chunk$set(fig.path='figure/minimal-', fig.align='center', fig.show='hold')
options(formatR.arrow=TRUE,width=90)
@

\title{intSEQ: Differential Analysis of RNA-seq Data with Integrated Likelihood Method}

\author{Yilun Zhang\\ David Rocke}

\maketitle
\section{Introduction}
This vignette is intended to give a brief introduction how to conduct differential analysis with RNA-seq data by means of the intSEQ R package. For further details of the methods, please consult [first paper], [second paper].

Consider the case we have RNA-seq count data arranged in a matrix that each columns describe a sample, and each row describe a genomic event (gene/exon/isoform). We denote the count in $i$th row and of $j$th group as $Y_{ij}$. Assume we have a predictor variable $X$, can be treatment/control group,  dose of radiation, etc, which may or may or affect the level of expression across samples. We want to determine if it exist any pattern between the predictor $X$ and different samples in each row.

The negative binomial distribution can be seen as Poisson-gamma mixture.  If $Y\sim$Poisson$(\lambda)$, and $\lambda$ is a random variable following Gamma distribution with shape parameter $1/\theta$ and rate $\frac{1}{\mu\theta}$. Then $Y$ has negative binomial distribution with mean parameter $\mu=E(Y)$ and dispersion parameter $\theta$. The variance function of negative binomial distribution is \[
V(\mu)=\mu+\theta\mu^2
\]

Many exsiting methods models RNA-seq data with negative binomial model. However, many of them suffers from false postive problem, that is, there are more than expected rejections occur. [first paper] suggests it may due to unaccounted variability of estimated dispersion parameters. The integrated likelihood method integrate the likelhood over the support of dispersion parameter rather than using a point estimator of the dispersion to control the false positive. It seems outperform other methods that also controls the false postive in term of higher power when the sample size is moderated. 

\section{Prepare the data}
\subsection{Read the data}
The users should arrange data into a numeric matrix with rows corresponds to genomic event (such as genes), and columns corresponds to samples. We also accept object of class "DGEList" in edgeR.

We use the Montgomery and Pickrell data as an example. The data set is RNA-Seq of RNA from lymphoblastoid cell lines from 129 individuals from the HapMap project. There were 60 from the above-referenced CEU subset and 69 from the Yoruba people in Ibadan, Nigeria (YRI). 52,580 unique genes of which 8,124 had a count of at least 129 across the 129 samples. We choose 10 CEU and 10 YRI individuals to conduct differential analysis.

<<read-data ,message=FALSE>>=
library(intSEQ)
data("count.data")
data("condition")
count = count.data[ , c(1:10, 61:70)]
cond = condition[c(1:10, 61:70)]
count[1:10,]
cond
@
\subsection{Filtering}
Since almost all existing methods have very low power for low expressed gene. We recommend filter out those genes with small average row count.
<<filter, eval=FALSE>>=
count = count[rowMeans(count) >= 1,]
@
\section{intSEQ Approach}
\subsection{Normalization}
The intSEQ function has a built-in normalization method "TMM". The users can use this method by setting "normalize=TRUE". Please don't normalize the count data yourself. Any non-integer input of count.data will cause error.

\subsection{Integrated Likelihood Ratio Test}
The intSEQ function will estimate the Cox and Reid's estimator of dispersion, then fit the negative binomial model. After that, the likelihood will be integrated over the dispersion:\[
 		IL(\mu)=	L(Y|\mu)=\int L(Y|\mu,\theta)\pi(\theta|\mu)d\theta
 		\]
Then the integrated likelihood will be treated as likelihood function. The integrated likelihood ratio statistics is compared with a $\chi^2$ distribution.
<<intSEQ1>>=
res=intSEQ(count, cond)
@

Alternatively, we can use DGEList

<<intSEQ2, eval = FALSE>>=
library(edgeR)
dge=DGEList(counts=count, group=cond)
res2=intSEQ(dge)
@
\subsection{Display the Results}
There is a function named \emph{show} to display the result. The users can choose to sort the genes from p values small to large, sort the log fold change from large to small by changing argument \emph{sortby}.
<<show>>=
show(res, sortby = "pvalue", shownum = 10)
show(res, sortby = "LFC", shownum = 10)
@

\section{Choose the Best Methods}
We found the performance of methods fluctuant as the sample size differs. We suggest the strategy to simulate synthetic negative binomial distributed data many times and apply each methods to the simulated data. Then compare their null performance and power. The simulated data uses the means and dispersions estimated from the real data. If user set "null = TRUE", it will simulate two groups of RNA-seq data with same expression level each row and will run FPR analysis. Otherwise, it will use the means of two groups and then conduct power analysis.

\subsection{Null performance}
Suppose we want to repeat the study in previous section for 10 times with same sample size. More number of simulations are always recommended.
<<nullsim,warning=FALSE>>=
set.seed(100)
simu.res.null <- simuComp(res, nsamp=10, ntime = 10, null=TRUE)
@
The FPR performance can be shown by \emph{summary}, the FPR should be controlled under levels.
<<nullsummary>>=
summary(simu.res.null)
@

To plot the levels against FPR:
<<nullplot,  fig.width=10, fig.height=8, out.width='\\linewidth',warning=FALSE>>=
plotComp(simu.res.null, text = " 10 vs 10 Null")
@
The four method all maintained the expected size.

\subsection{Power Analysis}
This is similar with the null case, except setting the "null = FALSE":
<<fullsimu,warning=FALSE>>=
set.seed(100)
simu.res.full <- simuComp(res, nsamp=10, ntime = 10, null=FALSE)
@

The summary function first will display the discovery rate of four method under FDR level equals to the argument "fdrlevel" passed to \emph{simuComp}. Then we categorize genes into different groups with respect to their log fold change. The users can choose "small" to display power of genes that are diminutively different, "medium" and "large" for medium and large log fold change genes, and "all" for all genes.
<<fullsummary>>=
summary(simu.res.full, difflevel = "small")
summary(simu.res.full, difflevel = "all")
@

There will be four plot showing discovery rate for small, medium, large group genes.
<<fullplot,  fig.width=10, fig.height=10, out.width='\\linewidth',warning=FALSE>>=
par(mfrow=c(2,2))
plotComp(simu.res.full, text = "")
@
We recommend the users to use the method that has highest power with FPR controlled.


\section{Session Information}
<<>>=
sessionInfo()
@
\end{document}